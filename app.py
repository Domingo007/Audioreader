from io import BytesIO
import tempfile
from pathlib import Path
import os
import subprocess  # âœ… dodaj to

import streamlit as st
from dotenv import dotenv_values
from openai import OpenAI



# --- Konfiguracja Å›rodowiska i klienta OpenAI ---
env = dotenv_values(".env")
AUDIO_TRANSCRIBE_MODEL = "whisper-1"

@st.cache_resource
def get_openai_client():
    return OpenAI(api_key=env["OPENAI_API_KEY"])

openai_client = get_openai_client()

# --- Konfiguracja strony ---
st.set_page_config(page_title="AudioReader", page_icon="ğŸ§", layout="wide")

# --- Inicjalizacja sesji ---
if "video_transcript" not in st.session_state:
    st.session_state["video_transcript"] = ""

# --- Layout: 2 kolumny ---
col1, col2 = st.columns([1, 2])

# === LEWA KOLUMNA: upload + przetwarzanie ===
with col1:
    st.subheader("ğŸ“¤ Wczytaj plik wideo")
    video_file = st.file_uploader("Wybierz plik (MP4 lub MOV)", type=["mp4", "mov"])

    if video_file is not None:
        # Zapisz plik tymczasowo
        with tempfile.NamedTemporaryFile(delete=False, suffix=Path(video_file.name).suffix) as temp_video:
            temp_video.write(video_file.read())
            video_path = temp_video.name

      # ğŸ”§ KONWERSJA DO WAV przy uÅ¼yciu subprocess + jawna Å›cieÅ¼ka
            audio_path = video_path.rsplit(".", 1)[0] + ".wav"
        try:
            ffmpeg_path = "/usr/local/bin/ffmpeg"  # Å›cieÅ¼ka z `brew install ffmpeg`
            subprocess.run([
             ffmpeg_path, "-hide_banner", "-y",
            "-i", video_path,
            "-vn",
            audio_path
        ], check=True)
            st.success("ğŸ§ Audio wyodrÄ™bnione z wideo")
        except Exception as e:
            st.error(f"âŒ BÅ‚Ä…d konwersji przez ffmpeg: {e}")
            st.stop()

        # ğŸ”Š Odtwarzacz audio
        audio_bytes = Path(audio_path).read_bytes()
        st.audio(audio_bytes, format="audio/wav")

        # ğŸ“ TRANSKRYPCJA
        if st.button("ğŸ“ Transkrybuj plik wideo"):
            with st.spinner("â³ Transkrypcja w toku..."):
                with open(audio_path, "rb") as f:
                    transcript = openai_client.audio.transcriptions.create(
                        file=f,
                        model=AUDIO_TRANSCRIBE_MODEL,
                        response_format="verbose_json"
                    )
                    st.session_state["video_transcript"] = transcript.text

        # ğŸ¬ NAPISY
        if st.button("ğŸ¬ Wygeneruj napisy format (.srt)"):
            with st.spinner("â³ TworzÄ™ napisy..."):
                with open(audio_path, "rb") as f:
                    srt_result = openai_client.audio.transcriptions.create(
                        file=f,
                        model=AUDIO_TRANSCRIBE_MODEL,
                        response_format="srt"
                    )
                srt_file = BytesIO(srt_result.encode("utf-8"))
                srt_file.name = "napisy.srt"
                st.success("âœ… Napisy gotowe")
                st.download_button("â¬‡ï¸ Pobierz napisy", data=srt_file, file_name="napisy.srt")

# === PRAWA KOLUMNA: opis i transkrypcja ===
with col2:
    st.title("ğŸ§ AudioReader")
    st.markdown("""
    NarzÄ™dzie stworzone z myÅ›lÄ… o podcasterach â€“ umoÅ¼liwia automatyczne tworzenie transkrypcji wywiadÃ³w, 
    generowanie napisÃ³w oraz przygotowanie materiaÅ‚Ã³w do publikacji 
    w mediach spoÅ‚ecznoÅ›ciowych.
    """)

# === PEÅNA TRANSKRYPCJA POD OPISEM ===
if st.session_state["video_transcript"]:
    st.markdown("---")
    st.subheader("ğŸ“„ PeÅ‚na transkrypcja z pliku")
    st.text_area(
        "Transkrypcja",
        value=st.session_state["video_transcript"],
        height=400,
        disabled=True
    )
