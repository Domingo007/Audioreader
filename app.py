from io import BytesIO
import tempfile
from pathlib import Path
import os
import subprocess

import streamlit as st
from dotenv import dotenv_values
from openai import OpenAI

# --- Konfiguracja Å›rodowiska i klienta OpenAI ---
env = dotenv_values(".env")
AUDIO_TRANSCRIBE_MODEL = "whisper-1"

@st.cache_resource
def get_openai_client():
    return OpenAI(api_key=env["OPENAI_API_KEY"])

openai_client = get_openai_client()

# --- Konfiguracja strony ---
st.set_page_config(page_title="AudioReader", page_icon="ğŸ·", layout="wide")

# --- Inicjalizacja sesji ---
if "video_transcript" not in st.session_state:
    st.session_state["video_transcript"] = ""
if "summary_text" not in st.session_state:
    st.session_state["summary_text"] = ""
if "key_topics" not in st.session_state:
    st.session_state["key_topics"] = []
if "timestamped_transcript" not in st.session_state:
    st.session_state["timestamped_transcript"] = ""
for i in range(1, 4):
    if f"clip_{i}_desc" not in st.session_state:
        st.session_state[f"clip_{i}_desc"] = ""
if "youtube_description" not in st.session_state:
    st.session_state["youtube_description"] = ""

# === PRAWA KOLUMNA: opis ===
st.title("ğŸ· AudioReader")
st.markdown("""
NarzÄ™dzie stworzone z myÅ›lÄ… o podcasterach â€“ umoÅ¼liwia automatyczne tworzenie transkrypcji wywiadÃ³w, 
generowanie napisÃ³w oraz przygotowanie materiaÅ‚Ã³w do publikacji 
w mediach spoÅ‚ecznoÅ›ciowych.

**Uwaga:** 
Przed wczytaniem nowego pliku naleÅ¼y odÅ›wieÅ¼yÄ‡ stronÄ™, aby wyczyÅ›ciÄ‡ pamiÄ™Ä‡ poprzedniego pliku.
ğŸ“¦ **Maksymalny rozmiar pliku: 200MB**
""")

# === LEWA KOLUMNA: upload + przetwarzanie ===
col1, col2 = st.columns([1, 2])

with col1:
    st.subheader("ğŸ“„ Wczytaj plik wideo")
    video_file = st.file_uploader("Wybierz plik (MP4 lub MOV)", type=["mp4", "mov"])

    if video_file is not None:
        st.write(f"ğŸ“¦ Rozmiar pliku: {video_file.size / (1024 * 1024):.2f} MB")

        with tempfile.NamedTemporaryFile(delete=False, suffix=Path(video_file.name).suffix) as temp_video:
            temp_video.write(video_file.read())
            video_path = temp_video.name

        audio_path = video_path.rsplit(".", 1)[0] + ".mp3"
        try:
            ffmpeg_path = "/usr/local/bin/ffmpeg"
            subprocess.run([
                ffmpeg_path, "-hide_banner", "-y",
                "-i", video_path,
                "-vn", "-ar", "44100", "-ac", "1", "-b:a", "128k",
                audio_path
            ], check=True)
            st.success("ğŸ· Audio wyodrÄ™bnione z wideo")
        except Exception as e:
            st.error(f"âŒ BÅ‚Ä…d konwersji przez ffmpeg: {e}")
            st.stop()

        audio_bytes = Path(audio_path).read_bytes()
        st.audio(audio_bytes, format="audio/mp3")

        with open(audio_path, "rb") as f:
            st.download_button("â¬‡ï¸ Pobierz audio (.mp3)", data=f, file_name="audio_z_wideo.mp3")

        if st.button("ğŸ“ Transkrybuj plik wideo"):
            with st.spinner("â³ Transkrypcja w toku..."):
                with open(audio_path, "rb") as f:
                    transcript = openai_client.audio.transcriptions.create(
                        file=f,
                        model=AUDIO_TRANSCRIBE_MODEL,
                        response_format="verbose_json"
                    )
                    st.session_state["video_transcript"] = transcript.text

        if st.button("ğŸ¯ StwÃ³rz transkrypcjÄ™ ze znacznikami czasowymi"):
            with st.spinner("ğŸ“š TworzÄ™ transkrypcjÄ™ ze znacznikami czasu..."):
                with open(audio_path, "rb") as f:
                    transcript_data = openai_client.audio.transcriptions.create(
                        file=f,
                        model=AUDIO_TRANSCRIBE_MODEL,
                        response_format="verbose_json"
                    )

                segments = transcript_data.segments
                timestamped_text = []

                for seg in segments:
                    start_time = int(seg.start)
                    minutes = start_time // 60
                    seconds = start_time % 60
                    timestamp = f"{minutes:02d}:{seconds:02d}"
                    text = seg.text.strip()
                    timestamped_text.append(f"{timestamp} - {text}")

                final_transcript = "\n".join(timestamped_text)
                st.session_state["timestamped_transcript"] = final_transcript

    # Transkrypcja peÅ‚na - pobieranie
    if st.session_state.get("video_transcript"):
        txt_file = BytesIO(st.session_state["video_transcript"].encode("utf-8"))
        txt_file.name = "transkrypcja.txt"
        st.download_button("â¬‡ï¸ Pobierz transkrypcjÄ™ (.txt)", data=txt_file, file_name="transkrypcja.txt")

    # Transkrypcja ze znacznikami - podglÄ…d + pobieranie
    if st.session_state.get("timestamped_transcript"):
        st.text_area("ğŸ“˜ Transkrypcja ze znacznikami czasowymi", value=st.session_state["timestamped_transcript"], height=400)
        ts_file = BytesIO(st.session_state["timestamped_transcript"].encode("utf-8"))
        ts_file.name = "transkrypcja_ze_znacznikami.txt"
        st.download_button("â¬‡ï¸ Pobierz transkrypcjÄ™ ze znacznikami", data=ts_file, file_name="transkrypcja_ze_znacznikami.txt")

with col2:
    if st.session_state.get("video_transcript"):
        st.markdown("---")
        st.subheader("ğŸ“„ PeÅ‚na transkrypcja z pliku")
        st.text_area("Transkrypcja", value=st.session_state["video_transcript"], height=400, disabled=True)

        if st.button("ğŸ“Œ Podsumuj rozmowÄ™"):
            with st.spinner("ğŸ” AnalizujÄ™ transkrypcjÄ™..."):
                system_prompt = "JesteÅ› asystentem do analizy rozmÃ³w. Podsumuj rozmowÄ™ w 3-4 zdaniach."
                user_prompt = st.session_state["video_transcript"]

                response = openai_client.chat.completions.create(
                    model="gpt-3.5-turbo",
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_prompt}
                    ]
                )

                result = response.choices[0].message.content.strip()
                st.session_state["summary_text"] = result

                topic_prompt = "Wypisz dokÅ‚adnie 5 najwaÅ¼niejszych tematÃ³w poruszonych w rozmowie w postaci punktÃ³w."
                topic_response = openai_client.chat.completions.create(
                    model="gpt-3.5-turbo",
                    messages=[
                        {"role": "system", "content": topic_prompt},
                        {"role": "user", "content": user_prompt}
                    ]
                )

                topic_lines = topic_response.choices[0].message.content.strip().split("\n")
                cleaned_topics = []
                for line in topic_lines:
                    stripped = line.strip()
                    if stripped:
                        if ". " in stripped:
                            cleaned_topics.append(stripped.split(". ", 1)[-1])
                        else:
                            cleaned_topics.append(stripped)
                st.session_state["key_topics"] = cleaned_topics[:5]

    if st.session_state.get("summary_text"):
        st.markdown("---")
        st.subheader("ğŸ§ Podsumowanie rozmowy")
        st.write(st.session_state["summary_text"])

    if st.session_state.get("key_topics"):
        st.subheader("ğŸ”‘ NajwaÅ¼niejsze tematy rozmowy:")
        for i, topic in enumerate(st.session_state["key_topics"], start=1):
            st.markdown(f"**{i}.** {topic}")

# === KLIPY DO SOCIAL MEDIÃ“W ===
st.markdown("---")
st.header("ğŸ¬ Klipy do social mediÃ³w")

for i in range(1, 4):
    st.markdown(f"## ğŸ¥ Klip {i} (max 1 minuta)")
    clip = st.file_uploader(f"Wczytaj Klip {i}", type=["mp4", "mov"], key=f"clip_{i}")

    if clip:
        with tempfile.NamedTemporaryFile(delete=False, suffix=Path(clip.name).suffix) as temp_clip:
            temp_clip.write(clip.read())
            clip_path = temp_clip.name

        if st.button(f"âœï¸ StwÃ³rz opis i hashtagi dla Klipu {i}"):
            clip_audio_path = clip_path.rsplit(".", 1)[0] + ".mp3"
            subprocess.run([
                "/usr/local/bin/ffmpeg", "-hide_banner", "-y",
                "-i", clip_path, "-vn", clip_audio_path
            ], check=True)

            with open(clip_audio_path, "rb") as f:
                transcription = openai_client.audio.transcriptions.create(
                    file=f,
                    model=AUDIO_TRANSCRIBE_MODEL,
                    response_format="text"
                )

            transcript_text = transcription.strip()

            description_prompt = (
                "Na podstawie poniÅ¼szej transkrypcji stwÃ³rz krÃ³tki opis (max 300 znakÃ³w) filmu do mediÃ³w spoÅ‚ecznoÅ›ciowych oraz wygeneruj 10 unikalnych hashtagÃ³w oddzielonych spacjÄ…. Nie powtarzaj hashtagÃ³w."
            )

            response = openai_client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": description_prompt},
                    {"role": "user", "content": transcript_text}
                ]
            )

            output = response.choices[0].message.content.strip()
            st.session_state[f"clip_{i}_desc"] = output

    if st.session_state.get(f"clip_{i}_desc"):
        st.text_area(f"Opis + Hashtagi Klip {i}", value=st.session_state[f"clip_{i}_desc"], height=180)

# === OPIS DO YOUTUBE ===
st.markdown("---")
st.header("ğŸ“º Opis do YouTube")
if st.button("ğŸ“˜ Generuj opis na YouTube"):
    with st.spinner("ğŸš° GenerujÄ™ opis na YouTube na podstawie treÅ›ci z klipÃ³w i tematÃ³w..."):
        combined_info = "\n\n".join(
            [st.session_state[f"clip_{i}_desc"] for i in range(1, 4) if st.session_state[f"clip_{i}_desc"]]
        )
        key_topics = "\n".join(st.session_state["key_topics"])

        yt_prompt = (
            "Na podstawie poniÅ¼szych danych stwÃ³rz jeden spÃ³jny i zwiÄ™zÅ‚y akapit opisu filmu na YouTube (maksymalnie 500 znakÃ³w). Dodaj na koÅ„cu dokÅ‚adnie 10 unikalnych hashtagÃ³w po przecinku."
            f"Opisy:\n{combined_info}\n\nTematy:\n{key_topics}"
        )

        yt_response = openai_client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": yt_prompt},
                {"role": "user", "content": "Wygeneruj opis na YouTube."}
            ]
        )

        youtube_output = yt_response.choices[0].message.content.strip()
        st.session_state["youtube_description"] = youtube_output

if st.session_state.get("youtube_description"):
    st.text_area("Opis YouTube", value=st.session_state["youtube_description"], height=250)
